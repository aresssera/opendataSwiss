{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all datasets and the according attribute values which contain (at least) one link without _https_ which also works with the replaced protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install urlextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'urlextract'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-758fcbb0ba86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0murlextract\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mURLExtract\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mextractor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'urlextract'"
     ]
    }
   ],
   "source": [
    "import requests     # 2.18.4\n",
    "import json         # 2.0.9\n",
    "import pandas as pd # 0.23.0\n",
    "import numpy as np\n",
    "import ast\n",
    "from urlextract import URLExtract as extract\n",
    "extractor = extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BFE Abnahme\n",
    "packages = 'https://ckan.ogdch-abnahme.clients.liip.ch/api/3/action/package_search?fq=organization:(bundesamt-fur-energie-bfe)&rows=500'\n",
    "\n",
    "# Make the HTTP request\n",
    "response = requests.get(packages)\n",
    "\n",
    "# Use the json module to load CKAN's response into a dictionary\n",
    "response_dict = json.loads(response.content)\n",
    "\n",
    "# Check the contents of the response\n",
    "assert response_dict['success'] is True  # make sure if response is OK\n",
    "\n",
    "# Get a list of all publications and their information (each publication is a dictionary)\n",
    "data = response_dict['result']['results'].copy()\n",
    "\n",
    "# get all upper keys\n",
    "allKeys = []\n",
    "\n",
    "# store information about each dataset in a frame\n",
    "df = pd.DataFrame(data)[['id','title','url', 'relations', 'resources']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_url(url):\n",
    "  try:\n",
    "    get = requests.head(url)\n",
    "\n",
    "    if get.status_code < 400:\n",
    "      return True\n",
    "    else:\n",
    "      return False\n",
    "\n",
    "  except requests.exceptions.RequestException as e:\n",
    "    raise SystemExit(f\"{url}: is NOT reachable \\nErr: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addHTTPS(url):\n",
    "  adjusted = url.replace(\"http:\", \"https:\" )\n",
    "  adjusted = adjusted.replace(\"www\", \"https://www\" )\n",
    "\n",
    "  return adjusted.replace(\"https://https://www\", \"https://www\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addHTTP(url):\n",
    "  adjusted = url.replace(\"www\", \"http://www\")\n",
    "  \n",
    "  return adjusted.replace(\"http://http://www\", \"http://www\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURLs(urls):\n",
    "  \n",
    "  links = []\n",
    "\n",
    "  for url in urls:\n",
    "\n",
    "    url_modified    = ''\n",
    "    # only store links which are faulty or need a protocol update (https)\n",
    "    needsToBeListed = False\n",
    "\n",
    "    if 'https' in url:\n",
    "      working = check_url(url)\n",
    "\n",
    "      if not working:\n",
    "        needsToBeListed = True\n",
    "\n",
    "\n",
    "    else:\n",
    "      \n",
    "      url_modified = addHTTPS(url)\n",
    "      working = check_url(url_modified)\n",
    "\n",
    "      if working:\n",
    "        needsToBeListed = True\n",
    "        \n",
    "      else:\n",
    "        # does not change http: urls\n",
    "        url_modified = addHTTPS(url)\n",
    "        working = check_url(url)\n",
    "\n",
    "        if not working:\n",
    "          url_modified = ''\n",
    "          needsToBeListed = True\n",
    "\n",
    "    if not needsToBeListed:\n",
    "      continue\n",
    "    \n",
    "\n",
    "    links.append([url, url_modified])\n",
    "\n",
    "  return links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns=['dataset_name', 'type', 'attribute', 'id', 'old_value', 'new_value'])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['url', 'relations']\n",
    "\n",
    "completeList = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  print(index)\n",
    "  dataset_name = row['title']['de']\n",
    "  id           = row['id']\n",
    "  for col in cols:\n",
    "  \n",
    "    \n",
    "    \n",
    "    att_type = 'dataset'\n",
    "    att      = col\n",
    "    val      = row[col]\n",
    "\n",
    "\n",
    "    liste = []\n",
    "\n",
    "\n",
    "    if col == 'resources':\n",
    "      att_type = 'resources'\n",
    "      #change att\n",
    "      print('nichts')\n",
    "\n",
    "\n",
    "    else:\n",
    "      print(val)\n",
    "      if type(val) == str:\n",
    "        liste = checkString(val)\n",
    "\n",
    "      else:\n",
    "        liste = checkString(str(val))\n",
    "\n",
    "\n",
    "    if len(liste) == 0:\n",
    "      continue\n",
    "    else:\n",
    "      for elem in liste:\n",
    "        completeList.append([dataset_name, att_type, att, id, elem[0], elem[1]])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = ['http://www.google.ch', 'https://www.google.ch', 'www.google.ch', 'https://data.geo.admin.ch/ch.bfe.windenergie-geschwindigkeit_h150/windenergie-geschwindigkeit_h150/windenergie-geschwindigkeit_h150_2056.fgdb.zip']\n",
    "markedURLs = checkString(str(urls))\n",
    "\n",
    "print(len(urls))\n",
    "print(len(markedURLs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkString(string):\n",
    "  print('checkString')\n",
    "\n",
    "  urls = extractor.find_urls(string)\n",
    "\n",
    "  # first remove elements which are not actual links\n",
    "  urls = [url for url in urls if ('http' in url) or ('www' in url)]\n",
    "  \n",
    "\n",
    "  return getURLs(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a string input\n",
    "def fromString(string):\n",
    "     \n",
    "     needsToBeListed = False\n",
    "     urls = extractor.find_urls(string)\n",
    "     # first remove elements which are not actual links\n",
    "     urls = [url for url in urls if 'http' in url or 'www' in url]\n",
    "\n",
    "     modified_string = '-'\n",
    "     \n",
    "     for url in urls:\n",
    "          \n",
    "          print(url)\n",
    "\n",
    "          working      = False\n",
    "          url_modified = ''\n",
    "          \n",
    "          if 'https://' in url:\n",
    "            working = check_url(url)\n",
    "\n",
    "            if not working:\n",
    "              needsToBeListed = True\n",
    "\n",
    "          # change to https://\n",
    "          else:\n",
    "            url_modified = addHTTPS(url)\n",
    "            working = check_url(url_modified)\n",
    "\n",
    "            # adds links which work with https\n",
    "            if working:\n",
    "              needsToBeListed = True\n",
    "            \n",
    "            # check if the links work with http\n",
    "            else:\n",
    "              url_modified = addHTTP(url)\n",
    "              working = check_url(url)\n",
    "\n",
    "          \n",
    "          if working:\n",
    "            modified_string = string.replace(url, url_modified)\n",
    "\n",
    "          print(modified_string)\n",
    "          print()\n",
    "               \n",
    "     print()\n",
    "     if needsToBeListed:\n",
    "    \n",
    "          return [string, modified_string]\n",
    "     else:\n",
    "          return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromDictionary(d):\n",
    "\n",
    "    changed  = False\n",
    "\n",
    "    for key in d.keys():\n",
    "\n",
    "        val      = d[key]\n",
    "        isString = True\n",
    "        \n",
    "\n",
    "        if type(val) not in [dict, str, list]:\n",
    "            continue\n",
    "        elif type(val) != str:\n",
    "            isString = False\n",
    "            val = str(val)\n",
    "\n",
    "        urls = extractor.find_urls(val)\n",
    "\n",
    "        if len(urls) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for url in urls:\n",
    "\n",
    "                working = False\n",
    "\n",
    "                if not any(prefix in url for prefix in ['www', 'http']):\n",
    "                    continue\n",
    "                elif 'https://' in url:\n",
    "                    continue\n",
    "                else:\n",
    "                    #first check if the adjusted url works, then replace it in the original\n",
    "\n",
    "                    working, adjusted_url = testAdjustedURL(url)\n",
    "\n",
    "                    if working:\n",
    "                        changed = True\n",
    "\n",
    "                        if isString:\n",
    "                            d[key] = val.replace(url, adjusted_url)\n",
    "                        else:\n",
    "                            d[key] = ast.literal_eval(val.replace(url, adjusted_url))\n",
    "\n",
    "\n",
    "    if changed:\n",
    "        return [d]\n",
    "    else:\n",
    "        return []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
